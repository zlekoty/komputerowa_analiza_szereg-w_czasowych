\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[export]{adjustbox}
\usepackage{mathtools,amsthm,amssymb,icomma,upgreek,xfrac,enumerate, bbm,titlesec,lmodern,polski,derivative,geometry,multicol,titling,graphicx,url,amsmath,caption,lipsum,float,longtable,booktabs}
\usepackage[table,xcdraw]{xcolor}
\usepackage[hidelinks,breaklinks,pdfusetitle,pdfdisplaydoctitle]{hyperref}
\usepackage{listings}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{light-gray}{gray}{0.95}
\setlength{\droptitle}{-1cm}
\mathtoolsset{showonlyrefs,mathic}
\title{Komputerowa analiza szeregów czasowych raport 1}
\author{Natalia Klepacka, Joanna Kołaczek}
\date{21.12.2022}
\newtheoremstyle{break}
{\topsep}{\topsep}%
{\normalfont}{}%
{\bfseries}{}%
{\newline}{}%
\theoremstyle{break}

\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\Large\bfseries}
\titleformat*{\subsubsection}{\large\bfseries}
\titleformat*{\paragraph}{\large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}
\renewcommand{\lstlistingname}{Kod}% Listing -> Kod
\renewcommand{\lstlistlistingname}{Lista Kodów}% List of Listings -> Lista kodów
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}

\graphicspath{{obrazki/}}


\begin{document}
	\maketitle
	\tableofcontents
	\clearpage
\section{Wstęp}
	Niniejszy raport powstał na potrzeby realizacji laboratorium z Komputerowej Analizy Szeregów Czasowych, prowadzonych przez mgr Justynę Witulską, do wykładu prof. Agnieszki Wyłomańskiej.
	Będziemy analizować dane dotyczące poziomu szczęścia w wybranych krajach na świecie, oraz dane dotyczące wpływu na szczęście poziomu PKB na osobę (w dalszej części raportu, będziemy je określać skrótowo jako szczęście i PKB). Po usunięciu wartości brakujących, dysponujemy próbami o wielkości~791. Dane pochodzą \href{https://www.kaggle.com/datasets/eliasturk/world-happiness-based-on-cpi-20152020}{\textit{z tej strony}}. Są to wyniki uzyskane przez Instytut Gallupa, w ankietach badających poziom szczęścia oraz jego możliwe indykatory, zebrane  w latach 2015-2020. W raporcie przeprowadzimy analizę jednowymiarową dla dwóch zmiennych oraz zwizualizujemy je przy pomocy histogramu, dystrybuanty empirycznej oraz boxplotu. Następnie wyestymujemy współczynniki w klasycznym modelu regresji, aby na końcu sprawdzić czy uzyskane residua spełniają oczekiwane założenia.
	
	Życzymy Czytelnikowi miłej lektury.
	
\section{Analiza jednowymiarowa zmiennej zależnej oraz zmiennej niezależnej}

W przeprowadzanej przez nas analizie, zmienną zależną jest \textbf{szczęście}, natomiast zmienną niezależną jest \textbf{PKB}. Rozkład danych możemy zobaczyć na histogramach [\ref{fig:hist}]. Zauważmy, że rozkład szczęścia wydaje się bardziej symetryczny niż rozkład PKB, który sprawia wrażenie lewoskośnego. Jednakże, niestety na pierwszy rzut oka, nie przypominają nam one żadnego ze znanych rozkładów.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.43]{hist.pdf}
		\caption{Histogramy}
		\label{fig:hist}
	\end{center}
\end{figure}

Dystrybuanty empiryczne [\ref{fig:distr}] pokazują z jakim prawdopodobieństwem natrafimy na kolejno szczęście i PKB mniejsze bądź równe od danej wartości. Gdy spojrzymy na dystrybuantę szczęścia, przypomina ona dystrybuantę rozkładu normalnego, o wariancji większej niż wariancja standardowego rozkładu normalnego. W przypadku dystrybuanty PKB, również przypomina ona rozkład normalny, z przesuniętą średnią. 

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.43]{distr.pdf}
		\caption{Dystrybuanta empiryczna}
		\label{fig:distr}
	\end{center}
\end{figure}

Wykres pudełkowy (ang. \textit{boxplot}) [\ref{fig:box}] jest to graficzna reprezentacja mediany oraz kwartyli. Wąsy mają długość półtorej wartości rozstępu międzykwartylowego. Co ciekawe, w naszych danych nie pojawiły się wartości odstające, zatem możemy sądzić, że dane zostały rzetelnie zebrane a ryzyko przeprowadzenia błędnej analizy (nieodzwierciedlającej rzeczywistych trendów) jest mniejsze.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.43]{box.pdf}
		\caption{Boxploty}
		\label{fig:box}
	\end{center}
\end{figure}

W tabeli [\ref{table}] podsumowałyśmy najistotniejsze miary położenia, rozproszenia, spłaszczenia i skośności. Rzeczwiście skośność którą odczytałyśmy z histogramu dla PKB jest ujemna (zatem rozkład jest lewoskośny), natomiast skośność dla szczęścia jest niewielka. Przypuszczenia z wykresu dystrybuanty empirycznej również się sprawdziły - wariancja szczęścia jest większa od jeden. 



\begin{table}[H]
	\centering
	\begin{tabular}{|ll|l|l|}
		\hline
		\rowcolor[HTML]{C0C0C0} 
		\multicolumn{2}{|l|}{\cellcolor[HTML]{C0C0C0}Miary}                             & Poziom szczęścia & PKB na osobe \\ \hline
		\multicolumn{1}{|l|}{}                               & średnia arytmetyczna     & 5.47             & 0.93         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & średnia geometryczna     & 5.23             & 0.58         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & średnia harmoniczna      & 5.35             & 0.81         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & średnia ucinana 10\%     & 5.47             & 0.94         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & mediana Q2               & 5.48             & 0.99         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & Q1                       & 4.59             & 0.64         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{położenia}    & Q3                       & 6.30             & 1.22         \\ \hline
		\multicolumn{1}{|l|}{}                               & rozstęp                  & 5.24             & 2.08         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & rozstęp międzykwartylowy & 1.70             & 0.58         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & wariancja nieobciążona   & 1.26             & 0.14         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{}                               & odchylenie standardowe   & 1.12             & 0.38         \\ \cline{2-4} 
		\multicolumn{1}{|l|}{rozproszenia} & współczynnik zmienności  & 20.52            & 41.33        \\ \hline
		\multicolumn{1}{|l|}{spłaszczenia}                   & kurtoza                  & 2.25             & 2.31         \\ \hline
		\multicolumn{1}{|l|}{skośności}                      & skośność                 & -0.01            & -0.36        \\ \hline
	\end{tabular}
\caption{\label{table}Zestawienie statystyk.}
\end{table}
	
\section{Analiza zależności liniowej pomiędzy zmienną zależną a zmienną niezależną}

\subsection{Wykres rozproszenia i określenie zależności}

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.43]{plot1.pdf}
		\caption{wykres rozproszenia}
		\label{fig:rozproszenie}
	\end{center}
\end{figure}

Na podstawie wykresu rozproszenia [\ref{fig:rozproszenie}] możemy stwierdzić, że zależność pomiędzy zmiennymi prawdopodobnie jest liniowa.

\subsection{Punktowa estymacja współczynników}

Współczynniki regresji liniowej wyznaczamy ze wzorów
\begin{equation}
\left\{ \begin{array}{ll}
	\beta_{1} = r\frac{S_{y}}{S_{x}}\\
	\beta_{0} = \bar{y} - r\beta_{1}\bar{x}
\end{array} \right.,
\end{equation} gdzie
\begin{equation}
	r = \frac{1}{n-1}\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{S_{x}S_{y}},
\end{equation}
\begin{equation}
	S_{x} = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}},
\end{equation}
\begin{equation}
	S_{y} = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}},
\end{equation}
\begin{equation}
	\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_{i},
\end{equation}
\begin{equation}
	\bar{y} = \frac{1}{n}\sum_{i=1}^{n}y_{i}.
\end{equation}

Wzory te zostały wyznaczone przy pomocy metody najmniejszych kwadratów.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.43]{plot2.pdf}
		\caption{wykres rozproszenia z zaznaczoną prostą regresji}
		\label{fig:prosta}
	\end{center}
\end{figure}

Z powyższych wzorów otrzymaliśmy 
\begin{equation}
	\left\{ \begin{array}{ll}
		\beta_{1} \approx 2.32\\
		\beta_{0} \approx 3.32
	\end{array} \right..
\end{equation}
Współczynniki te opisują prostą widoczną na wykresie [\ref{fig:prosta}].

\subsection{Przedziałowa estymacja współczynników}

Z założenia o normalności rozkładu $\{\varepsilon\}_{i=1}^{n}$, przy braku znajomości jego wariancji możemy stwierdzić, że unormowane parametry $\beta_0$, $\beta_1$ mają rozkład t-studenta z n-2 stopniami swobody. Przedziały ufności przyjmują wtedy postać
\begin{equation}
\left\{ \begin{array}{ll}
	P\left(\hat{\beta}_{0}-t_{n-2}(1-\frac{\alpha}{2})S\sqrt{\frac{1}{n}+\frac{\bar{x}^{2}}{\sum_{i=1}^{n}(x_i-\bar{x})^2}} < \beta_{0} < \hat{\beta}_{0}+t_{n-2}(1-\frac{\alpha}{2})S\sqrt{\frac{1}{n}+\frac{\bar{x}^{2}}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}\right) = 1-\alpha\\
	P\left(\hat{\beta}_{1}-t_{n-2}(1-\frac{\alpha}{2})\frac{S}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}} < \beta_{1} < \hat{\beta}_{1}+t_{n-2}(1-\frac{\alpha}{2})\frac{S}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}}\right) = 1-\alpha
\end{array} \right.,
\end{equation} gdzie
\begin{equation}
	S = \sqrt{\frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{n-2}}.
\end{equation}
Przyjmując $\alpha = 0.05$ otrzymujemy zatem, że z 95\% prawdopodobieństwem
\begin{equation}
	\left\{ \begin{array}{ll}
		\beta_{1} \in (2.19, 2.44)\\
		\beta_{0} \in (3.20, 3.44)
	\end{array} \right..
\end{equation}

\subsection{Ocena poziomu zależności}

\subsection{Predykcja oraz jej przedziały ufności}

\subsection{Interpretacja wyników}

\section{Analiza residuów}

W tej części, przeprowadzimy analizę residuów. Dzięki temu możemy ocenić czy model regresji liniowej jest dobrym wyborem dla naszego zbioru danych. Pod nazwą residuum mamy na myśli różnicę między wyestymowaną wartością, a wartością rzeczywistą.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{res.pdf}
		\caption{Residua}
		\label{fig:res}
	\end{center}
\end{figure}

Na wykresie [\ref{fig:res}] przedstawione zostały residua z regresji liniowej szczęścia w zależności od PKB. Czerwona linia oznacza średnią, która jest bliska zeru. Na pierwszy rzut oka, widzimy że wariancja jest mniej więcej równa na całej długości osi zmiennej niezależnej. Aby upewnić się czy nasze przewidywanie jest słuszne, wykonamy test Levene'a jednorodności wariancji [\ref{levene}]. 

\begin{lstlisting}[language=Python, caption=Test Levene'a, label={levene}]
	stat, p_value = scipy.stats.levene(random.sample(residuals,350),random.sample(residuals,350))
	if p_value > 0.05:
		print("Wariancja jest raczej stala.")
	else:
		print("Wariancja raczej nie jest stala.")
		
	#output
	Wariancja jest raczej stala.
\end{lstlisting}

Po wykonaniu testu nie mamy podstaw aby odrzucić hipotezę zerową: "Wszystkie próbki są z populacji o równej wariancji". Teraz będziemy chciały sprawdzić czy residua są niezależne. Ponieważ na wykresie [\ref{fig:res}] trudno dostrzec zależność, wykonamy test Durbina-Watsona [\ref{durbin}].

\begin{lstlisting}[language=Python, caption=Test Levene'a, label={durbin}]
	from statsmodels.stats.stattools import durbin_watson as dwtest
	dwtest(resids=np.array(residuals))
	
	#output
	1.2617265161048754
\end{lstlisting}

Jeżeli wynik jest bliski 2 oznacza to, że residua nie są skorelowane. W naszym przypadku, test sugeruje dodatnią korelację, co możemy również zobrazować na wykresie [\ref{fig:acor}], który wykorzystuje funkcję \code{acf} z pakietu \code{statsmodels.tsa.stattools}, aby policzyć autokorelację.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{acor.pdf}
		\caption{Autokowariancja residuów}
		\label{fig:acor}
	\end{center}
\end{figure}

Na koniec, sprawdzimy jeszcze, czy rozkład residuów jest normalny. W tym celu porównamy ich histogram z gęstością rozkładu normalnego [\ref{fig:res_hist}]. 
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{res_hist.pdf}
		\caption{Rozkład residuów}
		\label{fig:res_hist}
	\end{center}
\end{figure}

 Ponieważ możemy mieć wątpliwości wynikające z różnic na wykresie, wykonamy test na normalność [\ref{norm}], który potwierdza, że residua prawdopodobnie nie mają oczekiwanego rozkładu.

\begin{lstlisting}[language=Python, caption=Test Levene'a, label={norm}]
	stat, p = scipy.stats.normaltest(residuals)
	if p > 0.05:
		print('Dane raczej pochodza z rozkladu normalnego')
	else:
		print('Dane raczej nie pochodza z rozkladu normalnego')
		
	#output
	Dane raczej nie pochodza z rozkladu normalnego
\end{lstlisting}

	
\section{Podsumowanie}
	Analizując przedstawione w raporcie statystyki możemy sformułować następujące wnioski i przypuszczenia dotyczące długości ogonów w populacji myszołowów rdzawosternych. Z histogramu widzimy, że badany rozkład przypomina rozkład normalny, jednak po obliczeniu skośności okazuje się, że różni się ona od skośności rozkładu normalnego, która wynosi zero. Podejrzewamy, iż może to być spowodowane licznością próby. Statystyczny myszołów rdzawosterny powinien mieć ogon o długości od $207,638$ do $236.66$ mm, (średnia arytmetyczna $\pm$ odchylenie standardowe). Biorąc średnią z populacji przewidujemy długość około $222,15$ mm. Wartości skrajne nie wpływają znacząco na wartość średniej - wiemy to po obliczeniu średniej Winsorowskiej ($222,182$ mm) i ucinanej ($222,104$ mm). 
	
	\section{Źródła}
	\begin{itemize}
		\item Wykłady
		\item \url{https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HawkTail.csv}
		\item \url{https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Descriptive-Statistics/Measures-of-Position/index.html}
		\item \url{https://www.investopedia.com/terms/w/winsorized_mean.asp}
	\end{itemize}
	
	
\end{document}